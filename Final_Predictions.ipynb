{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a final model we're going to predict 2020 games for this coming week! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import functions \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "pd.options.display.max_columns = 2000\n",
    "pd.options.display.max_rows = 2000\n",
    "import sqlite3\n",
    "from keras import layers \n",
    "from keras import models \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload dataset\n",
    "conn = sqlite3.connect('NFL_Modeling_Stats.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Home_Team</th>\n",
       "      <th>Away_Team</th>\n",
       "      <th>Home_Week</th>\n",
       "      <th>Away_Week</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Home_Pts_Scored</th>\n",
       "      <th>Away_Pts_Scored</th>\n",
       "      <th>Home_Pts_Al</th>\n",
       "      <th>Away_Pts_Al</th>\n",
       "      <th>Home_Win</th>\n",
       "      <th>Away_Win</th>\n",
       "      <th>Home_TDs</th>\n",
       "      <th>Away_TDs</th>\n",
       "      <th>Home_First_Sc</th>\n",
       "      <th>Away_First_Sc</th>\n",
       "      <th>Home_Second_Sc</th>\n",
       "      <th>Away_Second_Sc</th>\n",
       "      <th>Home_Third_Sc</th>\n",
       "      <th>Away_Third_Sc</th>\n",
       "      <th>Home_Fourth_Sc</th>\n",
       "      <th>Away_Fourth_Sc</th>\n",
       "      <th>Home_First_Al</th>\n",
       "      <th>Away_First_Al</th>\n",
       "      <th>Home_Second_Al</th>\n",
       "      <th>Away_Second_Al</th>\n",
       "      <th>Home_Third_Al</th>\n",
       "      <th>Away_Third_Al</th>\n",
       "      <th>Home_Fourth_Al</th>\n",
       "      <th>Away_Fourth_Al</th>\n",
       "      <th>Home_Off_Plys</th>\n",
       "      <th>Away_Off_Plys</th>\n",
       "      <th>Home_Rush_Plys</th>\n",
       "      <th>Away_Rush_Plys</th>\n",
       "      <th>Home_Pass_Plys</th>\n",
       "      <th>Away_Pass_Plys</th>\n",
       "      <th>Home_Fumbles</th>\n",
       "      <th>Away_Fumbles</th>\n",
       "      <th>Home_Yds_Ply</th>\n",
       "      <th>Away_Yds_Ply</th>\n",
       "      <th>Home_Yds_Rush</th>\n",
       "      <th>Away_Yds_Rush</th>\n",
       "      <th>Home_Yds_Pass</th>\n",
       "      <th>Away_Yds_Pass</th>\n",
       "      <th>Home_Total_Yds_Gm</th>\n",
       "      <th>Away_Total_Yds_Gm</th>\n",
       "      <th>Home_Total_Rush_Yds_Gm</th>\n",
       "      <th>Away_Total_Rush_Yds_Gm</th>\n",
       "      <th>Home_Total_Pass_Yds_Gm</th>\n",
       "      <th>Away_Total_Pass_Yds_Gm</th>\n",
       "      <th>Home_Yds_Ply_Al</th>\n",
       "      <th>Away_Yds_Ply_Al</th>\n",
       "      <th>Home_Yds_Rush_Al</th>\n",
       "      <th>Away_Yds_Rush_Al</th>\n",
       "      <th>Home_Yds_Pass_Al</th>\n",
       "      <th>Away_Yds_Pass_Al</th>\n",
       "      <th>Home_Total_Yds_Gm_Al</th>\n",
       "      <th>Away_Total_Yds_Gm_Al</th>\n",
       "      <th>Home_Total_Rush_Yds_Gm_Al</th>\n",
       "      <th>Away_Total_Rush_Yds_Gm_Al</th>\n",
       "      <th>Home_Total_Pass_Yds_Gm_Al</th>\n",
       "      <th>Away_Total_Pass_Yds_Gm_Al</th>\n",
       "      <th>Home_Off_Plys_Al</th>\n",
       "      <th>Away_Off_Plys_Al</th>\n",
       "      <th>Home_Rush_Plys_Al</th>\n",
       "      <th>Away_Rush_Plys_Al</th>\n",
       "      <th>Home_Pass_Plys_Al</th>\n",
       "      <th>Away_Pass_Plys_Al</th>\n",
       "      <th>Home_Completion_Rate</th>\n",
       "      <th>Away_Completion_Rate</th>\n",
       "      <th>Home_Pass_Att</th>\n",
       "      <th>Away_Pass_Att</th>\n",
       "      <th>Home_Pass_TDs</th>\n",
       "      <th>Away_Pass_TDs</th>\n",
       "      <th>Home_INTs</th>\n",
       "      <th>Away_INTs</th>\n",
       "      <th>Home_Sacks_Taken</th>\n",
       "      <th>Away_Sacks_Taken</th>\n",
       "      <th>Home_Rush_TDs</th>\n",
       "      <th>Away_Rush_TDs</th>\n",
       "      <th>Home_Rush_Att</th>\n",
       "      <th>Away_Rush_Att</th>\n",
       "      <th>Home_Pass_1Ds_Gm</th>\n",
       "      <th>Away_Pass_1Ds_Gm</th>\n",
       "      <th>Home_Rush_1Ds_Gm</th>\n",
       "      <th>Away_Rush_1Ds_Gm</th>\n",
       "      <th>Home_First_Ds_Gm</th>\n",
       "      <th>Away_First_Ds_Gm</th>\n",
       "      <th>Home_Third_Conv_Perc</th>\n",
       "      <th>Away_Third_Conv_Perc</th>\n",
       "      <th>Home_Fourth_Conv_Perc</th>\n",
       "      <th>Away_Fourth_Conv_Perc</th>\n",
       "      <th>Home_Sacks_Gm</th>\n",
       "      <th>Away_Sacks_Gm</th>\n",
       "      <th>Home_INT_Gm</th>\n",
       "      <th>Away_INT_Gm</th>\n",
       "      <th>Home_Fumbles_Caused</th>\n",
       "      <th>Away_Fumbles_Caused</th>\n",
       "      <th>Home_TO_Gm</th>\n",
       "      <th>Away_TO_Gm</th>\n",
       "      <th>Home_FG_Att</th>\n",
       "      <th>Away_FG_Att</th>\n",
       "      <th>Home_FG_Perc_Comp</th>\n",
       "      <th>Away_FG_Perc_Comp</th>\n",
       "      <th>Home_PAT_Att</th>\n",
       "      <th>Away_PAT_Att</th>\n",
       "      <th>Home_PAT_Perc_Comp</th>\n",
       "      <th>Away_PAT_Perc_Comp</th>\n",
       "      <th>Home_Punts</th>\n",
       "      <th>Away_Punts</th>\n",
       "      <th>Home_Avg_Punt_Yds_Gm</th>\n",
       "      <th>Away_Avg_Punt_Yds_Gm</th>\n",
       "      <th>Home_Avg_Punt_Ret_Yds_Gm</th>\n",
       "      <th>Away_Avg_Punt_Ret_Yds_Gm</th>\n",
       "      <th>Home_Avg_Punt_Ret_Yds_Opp_Gm</th>\n",
       "      <th>Away_Avg_Punt_Ret_Yds_Opp_Gm</th>\n",
       "      <th>Home_Total_Punt_Ret_Yds_Gm</th>\n",
       "      <th>Away_Total_Punt_Ret_Yds_Gm</th>\n",
       "      <th>Home_Total_Punt_Ret_Yds_Opp_Gm</th>\n",
       "      <th>Away_Total_Punt_Ret_Yds_Opp_Gm</th>\n",
       "      <th>Home_Punt_Ret_TD</th>\n",
       "      <th>Away_Punt_Ret_TD</th>\n",
       "      <th>Home_Punt_Ret_TD_Opp</th>\n",
       "      <th>Away_Punt_Ret_TD_Opp</th>\n",
       "      <th>Home_Avg_Kick_Ret_Yds_Gm</th>\n",
       "      <th>Away_Avg_Kick_Ret_Yds_Gm</th>\n",
       "      <th>Home_Avg_Kick_Ret_Yds_Opp_Gm</th>\n",
       "      <th>Away_Avg_Kick_Ret_Yds_Opp_Gm</th>\n",
       "      <th>Home_Kick_Ret_TD_Opp</th>\n",
       "      <th>Away_Kick_Ret_TD_Opp</th>\n",
       "      <th>Home_Kick_Ret_TD</th>\n",
       "      <th>Away_Kick_Ret_TD</th>\n",
       "      <th>Home_Penalty_Gm</th>\n",
       "      <th>Away_Penalty_Gm</th>\n",
       "      <th>Home_Penalty_Yds_Gm</th>\n",
       "      <th>Away_Penalty_Yds_Gm</th>\n",
       "      <th>Home_Playoff_app_5_yrs</th>\n",
       "      <th>Away_Playoff_app_5_yrs</th>\n",
       "      <th>Home_Draft_Pos</th>\n",
       "      <th>Away_Draft_Pos</th>\n",
       "      <th>Home_Week_Of_Szn</th>\n",
       "      <th>Away_Week_Of_Szn</th>\n",
       "      <th>Home_Perc_Pro_Bowl</th>\n",
       "      <th>Away_Perc_Pro_Bowl</th>\n",
       "      <th>Home_Year</th>\n",
       "      <th>Away_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Week_1_Bears</td>\n",
       "      <td>Bears</td>\n",
       "      <td>Packers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Away</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>254.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.6</td>\n",
       "      <td>47.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Week_1_Eagles</td>\n",
       "      <td>Eagles</td>\n",
       "      <td>Redskins</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Home</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>436.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>39.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>51.3</td>\n",
       "      <td>54.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Week_1_Jets</td>\n",
       "      <td>Jets</td>\n",
       "      <td>Bills</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Away</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>223.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>370.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.4</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Week_1_Vikings</td>\n",
       "      <td>Vikings</td>\n",
       "      <td>Falcons</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Home</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>269.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>345.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49.4</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Week_1_Dolphins</td>\n",
       "      <td>Dolphins</td>\n",
       "      <td>Ravens</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Away</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>200.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>14.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>643.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index Home_Team Away_Team  Home_Week  Away_Week Winner  \\\n",
       "0     Week_1_Bears     Bears   Packers        1.0        1.0   Away   \n",
       "1    Week_1_Eagles    Eagles  Redskins        1.0        1.0   Home   \n",
       "2      Week_1_Jets      Jets     Bills        1.0        1.0   Away   \n",
       "3   Week_1_Vikings   Vikings   Falcons        1.0        1.0   Home   \n",
       "4  Week_1_Dolphins  Dolphins    Ravens        1.0        1.0   Away   \n",
       "\n",
       "   Home_Pts_Scored  Away_Pts_Scored  Home_Pts_Al  Away_Pts_Al  Home_Win  \\\n",
       "0              3.0             10.0         10.0          3.0       0.0   \n",
       "1             32.0             27.0         27.0         32.0       1.0   \n",
       "2             16.0             17.0         17.0         16.0       0.0   \n",
       "3             28.0             12.0         12.0         28.0       1.0   \n",
       "4             10.0             59.0         59.0         10.0       0.0   \n",
       "\n",
       "   Away_Win  Home_TDs  Away_TDs  Home_First_Sc  Away_First_Sc  Home_Second_Sc  \\\n",
       "0       1.0       0.0       1.0            3.0            0.0             0.0   \n",
       "1       0.0       4.0       3.0            0.0           10.0             7.0   \n",
       "2       1.0       1.0       2.0            6.0            0.0             0.0   \n",
       "3       0.0       4.0       2.0           14.0            0.0             7.0   \n",
       "4       1.0       1.0       8.0            0.0           21.0            10.0   \n",
       "\n",
       "   Away_Second_Sc  Home_Third_Sc  Away_Third_Sc  Home_Fourth_Sc  \\\n",
       "0             7.0            0.0            0.0             0.0   \n",
       "1            10.0           14.0            0.0            11.0   \n",
       "2             0.0           10.0            3.0             0.0   \n",
       "3             0.0            7.0            0.0             0.0   \n",
       "4            21.0            0.0           10.0             0.0   \n",
       "\n",
       "   Away_Fourth_Sc  Home_First_Al  Away_First_Al  Home_Second_Al  \\\n",
       "0             3.0            0.0            3.0             7.0   \n",
       "1             7.0           10.0            0.0            10.0   \n",
       "2            14.0            0.0            6.0             0.0   \n",
       "3            12.0            0.0           14.0             0.0   \n",
       "4             7.0           21.0            0.0            21.0   \n",
       "\n",
       "   Away_Second_Al  Home_Third_Al  Away_Third_Al  Home_Fourth_Al  \\\n",
       "0             0.0            0.0            0.0             3.0   \n",
       "1             7.0            0.0           14.0             7.0   \n",
       "2             0.0            3.0           10.0            14.0   \n",
       "3             7.0            0.0            7.0            12.0   \n",
       "4            10.0           10.0            0.0             7.0   \n",
       "\n",
       "   Away_Fourth_Al  Home_Off_Plys  Away_Off_Plys  Home_Rush_Plys  \\\n",
       "0             0.0           65.0           57.0            15.0   \n",
       "1            11.0           71.0           58.0            31.0   \n",
       "2             0.0           66.0           63.0            21.0   \n",
       "3             0.0           49.0           67.0            38.0   \n",
       "4             0.0           47.0           73.0            12.0   \n",
       "\n",
       "   Away_Rush_Plys  Home_Pass_Plys  Away_Pass_Plys  Home_Fumbles  Away_Fumbles  \\\n",
       "0            22.0            45.0            30.0           0.0           0.0   \n",
       "1            13.0            39.0            44.0           0.0           0.0   \n",
       "2            25.0            41.0            37.0           1.0           2.0   \n",
       "3            17.0            10.0            46.0           0.0           1.0   \n",
       "4            46.0            32.0            26.0           1.0           0.0   \n",
       "\n",
       "   Home_Yds_Ply  Away_Yds_Ply  Home_Yds_Rush  Away_Yds_Rush  Home_Yds_Pass  \\\n",
       "0           3.9           3.7            3.1            2.1            5.1   \n",
       "1           6.1           6.9            4.0            2.2            8.0   \n",
       "2           3.4           5.9            3.2            5.1            4.3   \n",
       "3           5.5           5.1            4.5            4.3            9.8   \n",
       "4           4.3           8.8            1.8            5.8            5.9   \n",
       "\n",
       "   Away_Yds_Pass  Home_Total_Yds_Gm  Away_Total_Yds_Gm  \\\n",
       "0            6.8              254.0              213.0   \n",
       "1            8.6              436.0              398.0   \n",
       "2            6.9              223.0              370.0   \n",
       "3            6.6              269.0              345.0   \n",
       "4           14.6              200.0              643.0   \n",
       "\n",
       "   Home_Total_Rush_Yds_Gm  Away_Total_Rush_Yds_Gm  Home_Total_Pass_Yds_Gm  \\\n",
       "0                    46.0                    47.0                   208.0   \n",
       "1                   123.0                    28.0                   313.0   \n",
       "2                    68.0                   128.0                   155.0   \n",
       "3                   172.0                    73.0                    97.0   \n",
       "4                    21.0                   265.0                   179.0   \n",
       "\n",
       "   Away_Total_Pass_Yds_Gm  Home_Yds_Ply_Al  Away_Yds_Ply_Al  Home_Yds_Rush_Al  \\\n",
       "0                   166.0              3.9              3.7               2.1   \n",
       "1                   370.0              6.1              6.9               2.2   \n",
       "2                   242.0              3.4              5.9               5.1   \n",
       "3                   272.0              5.5              5.1               4.3   \n",
       "4                   378.0              4.3              8.8               5.8   \n",
       "\n",
       "   Away_Yds_Rush_Al  Home_Yds_Pass_Al  Away_Yds_Pass_Al  Home_Total_Yds_Gm_Al  \\\n",
       "0               3.1               6.8               5.1                 213.0   \n",
       "1               4.0               8.6               8.0                 398.0   \n",
       "2               3.2               6.9               4.3                 370.0   \n",
       "3               4.5               6.6               9.8                 345.0   \n",
       "4               1.8              14.6               5.9                 643.0   \n",
       "\n",
       "   Away_Total_Yds_Gm_Al  Home_Total_Rush_Yds_Gm_Al  Away_Total_Rush_Yds_Gm_Al  \\\n",
       "0                 254.0                       47.0                       46.0   \n",
       "1                 436.0                       28.0                      123.0   \n",
       "2                 223.0                      128.0                       68.0   \n",
       "3                 269.0                       73.0                      172.0   \n",
       "4                 200.0                      265.0                       21.0   \n",
       "\n",
       "   Home_Total_Pass_Yds_Gm_Al  Away_Total_Pass_Yds_Gm_Al  Home_Off_Plys_Al  \\\n",
       "0                      166.0                      208.0              57.0   \n",
       "1                      370.0                      313.0              58.0   \n",
       "2                      242.0                      155.0              63.0   \n",
       "3                      272.0                       97.0              67.0   \n",
       "4                      378.0                      179.0              73.0   \n",
       "\n",
       "   Away_Off_Plys_Al  Home_Rush_Plys_Al  Away_Rush_Plys_Al  Home_Pass_Plys_Al  \\\n",
       "0              65.0               22.0               15.0               30.0   \n",
       "1              71.0               13.0               31.0               44.0   \n",
       "2              66.0               25.0               21.0               37.0   \n",
       "3              49.0               17.0               38.0               46.0   \n",
       "4              47.0               46.0               12.0               26.0   \n",
       "\n",
       "   Away_Pass_Plys_Al  Home_Completion_Rate  Away_Completion_Rate  \\\n",
       "0               45.0              0.577778              0.600000   \n",
       "1               39.0              0.717949              0.681818   \n",
       "2               41.0              0.682927              0.648649   \n",
       "3               10.0              0.800000              0.717391   \n",
       "4               32.0              0.468750              0.884615   \n",
       "\n",
       "   Home_Pass_Att  Away_Pass_Att  Home_Pass_TDs  Away_Pass_TDs  Home_INTs  \\\n",
       "0           45.0           30.0            0.0            1.0        1.0   \n",
       "1           39.0           44.0            3.0            3.0        0.0   \n",
       "2           41.0           37.0            1.0            1.0        0.0   \n",
       "3           10.0           46.0            1.0            2.0        0.0   \n",
       "4           32.0           26.0            1.0            6.0        2.0   \n",
       "\n",
       "   Away_INTs  Home_Sacks_Taken  Away_Sacks_Taken  Home_Rush_TDs  \\\n",
       "0        0.0               5.0               5.0            0.0   \n",
       "1        0.0               1.0               1.0            1.0   \n",
       "2        2.0               4.0               1.0            0.0   \n",
       "3        2.0               1.0               4.0            3.0   \n",
       "4        0.0               3.0               1.0            0.0   \n",
       "\n",
       "   Away_Rush_TDs  Home_Rush_Att  Away_Rush_Att  Home_Pass_1Ds_Gm  \\\n",
       "0            0.0           15.0           22.0              10.0   \n",
       "1            0.0           31.0           13.0              13.0   \n",
       "2            1.0           21.0           25.0              12.0   \n",
       "3            0.0           38.0           17.0               4.0   \n",
       "4            2.0           12.0           46.0              10.0   \n",
       "\n",
       "   Away_Pass_1Ds_Gm  Home_Rush_1Ds_Gm  Away_Rush_1Ds_Gm  Home_First_Ds_Gm  \\\n",
       "0              10.0               3.0               1.0              16.0   \n",
       "1              15.0               9.0               0.0              22.0   \n",
       "2              11.0               3.0               8.0              17.0   \n",
       "3              16.0              10.0               5.0              18.0   \n",
       "4              17.0               1.0              10.0              12.0   \n",
       "\n",
       "   Away_First_Ds_Gm  Home_Third_Conv_Perc  Away_Third_Conv_Perc  \\\n",
       "0              13.0                  20.0                  16.0   \n",
       "1              15.0                  64.0                  38.0   \n",
       "2              23.0                  41.0                  50.0   \n",
       "3              27.0                  50.0                  25.0   \n",
       "4              31.0                  30.0                  63.0   \n",
       "\n",
       "   Home_Fourth_Conv_Perc  Away_Fourth_Conv_Perc  Home_Sacks_Gm  Away_Sacks_Gm  \\\n",
       "0                    0.0                    0.0            5.0            5.0   \n",
       "1                   50.0                  100.0            1.0            1.0   \n",
       "2                   50.0                    0.0            1.0            4.0   \n",
       "3                    0.0                  100.0            4.0            1.0   \n",
       "4                    0.0                  100.0            1.0            3.0   \n",
       "\n",
       "   Home_INT_Gm  Away_INT_Gm  Home_Fumbles_Caused  Away_Fumbles_Caused  \\\n",
       "0          0.0          1.0                  0.0                  0.0   \n",
       "1          0.0          0.0                  0.0                  0.0   \n",
       "2          2.0          0.0                  2.0                  1.0   \n",
       "3          2.0          0.0                  1.0                  0.0   \n",
       "4          0.0          2.0                  0.0                  1.0   \n",
       "\n",
       "   Home_TO_Gm  Away_TO_Gm  Home_FG_Att  Away_FG_Att  Home_FG_Perc_Comp  \\\n",
       "0         0.0         1.0          1.0          1.0                1.0   \n",
       "1         0.0         0.0          1.0          2.0                1.0   \n",
       "2         4.0         1.0          1.0          1.0                0.0   \n",
       "3         3.0         0.0          0.0          0.0                NaN   \n",
       "4         0.0         3.0          1.0          1.0                1.0   \n",
       "\n",
       "   Away_FG_Perc_Comp  Home_PAT_Att  Away_PAT_Att  Home_PAT_Perc_Comp  \\\n",
       "0                1.0           0.0           1.0                 0.0   \n",
       "1                1.0           3.0           3.0                 1.0   \n",
       "2                1.0           1.0           2.0                 0.0   \n",
       "3                NaN           4.0           0.0                 1.0   \n",
       "4                1.0           1.0           8.0                 1.0   \n",
       "\n",
       "   Away_PAT_Perc_Comp  Home_Punts  Away_Punts  Home_Avg_Punt_Yds_Gm  \\\n",
       "0                 1.0         8.0         9.0                  42.6   \n",
       "1                 1.0         3.0         5.0                  51.3   \n",
       "2                 1.0         7.0         3.0                  43.4   \n",
       "3                 0.0         5.0         3.0                  49.4   \n",
       "4                 1.0         6.0         1.0                  53.7   \n",
       "\n",
       "   Away_Avg_Punt_Yds_Gm  Home_Avg_Punt_Ret_Yds_Gm  Away_Avg_Punt_Ret_Yds_Gm  \\\n",
       "0                  47.6                       9.0                       1.0   \n",
       "1                  54.4                      11.5                      11.0   \n",
       "2                  43.3                       0.0                      10.0   \n",
       "3                  43.3                       0.0                      11.5   \n",
       "4                  56.0                       0.0                      14.5   \n",
       "\n",
       "   Home_Avg_Punt_Ret_Yds_Opp_Gm  Away_Avg_Punt_Ret_Yds_Opp_Gm  \\\n",
       "0                           1.0                           9.0   \n",
       "1                          11.0                          11.5   \n",
       "2                           0.0                           0.0   \n",
       "3                          11.5                           0.0   \n",
       "4                          14.5                           0.0   \n",
       "\n",
       "   Home_Total_Punt_Ret_Yds_Gm  Away_Total_Punt_Ret_Yds_Gm  \\\n",
       "0                        36.0                         1.0   \n",
       "1                        46.0                        11.0   \n",
       "2                         0.0                        10.0   \n",
       "3                         0.0                        46.0   \n",
       "4                         0.0                        29.0   \n",
       "\n",
       "   Home_Total_Punt_Ret_Yds_Opp_Gm  Away_Total_Punt_Ret_Yds_Opp_Gm  \\\n",
       "0                             1.0                            36.0   \n",
       "1                            11.0                            46.0   \n",
       "2                            10.0                             0.0   \n",
       "3                            46.0                             0.0   \n",
       "4                            29.0                             0.0   \n",
       "\n",
       "   Home_Punt_Ret_TD  Away_Punt_Ret_TD  Home_Punt_Ret_TD_Opp  \\\n",
       "0               0.0               0.0                   0.0   \n",
       "1               0.0               0.0                   0.0   \n",
       "2               0.0               0.0                   0.0   \n",
       "3               0.0               0.0                   0.0   \n",
       "4               0.0               0.0                   0.0   \n",
       "\n",
       "   Away_Punt_Ret_TD_Opp  Home_Avg_Kick_Ret_Yds_Gm  Away_Avg_Kick_Ret_Yds_Gm  \\\n",
       "0                   0.0                  0.000000                  0.000000   \n",
       "1                   0.0                  0.000000                 15.333333   \n",
       "2                   0.0                 10.000000                  0.000000   \n",
       "3                   0.0                 13.000000                 22.000000   \n",
       "4                   0.0                 19.666667                  9.000000   \n",
       "\n",
       "   Home_Avg_Kick_Ret_Yds_Opp_Gm  Away_Avg_Kick_Ret_Yds_Opp_Gm  \\\n",
       "0                      0.000000                      0.000000   \n",
       "1                     15.333333                      0.000000   \n",
       "2                      0.000000                     10.000000   \n",
       "3                     22.000000                     13.000000   \n",
       "4                      9.000000                     19.666667   \n",
       "\n",
       "   Home_Kick_Ret_TD_Opp  Away_Kick_Ret_TD_Opp  Home_Kick_Ret_TD  \\\n",
       "0                   0.0                   0.0               0.0   \n",
       "1                   0.0                   0.0               0.0   \n",
       "2                   0.0                   0.0               0.0   \n",
       "3                   0.0                   0.0               0.0   \n",
       "4                   0.0                   0.0               0.0   \n",
       "\n",
       "   Away_Kick_Ret_TD  Home_Penalty_Gm  Away_Penalty_Gm  Home_Penalty_Yds_Gm  \\\n",
       "0               0.0             10.0             10.0                107.0   \n",
       "1               0.0              6.0             12.0                 55.0   \n",
       "2               0.0              8.0              7.0                 67.0   \n",
       "3               0.0             11.0              9.0                100.0   \n",
       "4               0.0              9.0              4.0                 64.0   \n",
       "\n",
       "   Away_Penalty_Yds_Gm  Home_Playoff_app_5_yrs  Away_Playoff_app_5_yrs  \\\n",
       "0                 71.0                     1.0                     7.0   \n",
       "1                 96.0                     5.0                     0.0   \n",
       "2                 55.0                     0.0                     1.0   \n",
       "3                 78.0                     3.0                     5.0   \n",
       "4                 40.0                     1.0                     2.0   \n",
       "\n",
       "   Home_Draft_Pos  Away_Draft_Pos  Home_Week_Of_Szn  Away_Week_Of_Szn  \\\n",
       "0            73.0            30.0               1.0               1.0   \n",
       "1            22.0            15.0               1.0               1.0   \n",
       "2             3.0             9.0               1.0               1.0   \n",
       "3            18.0            14.0               1.0               1.0   \n",
       "4            13.0            22.0               1.0               1.0   \n",
       "\n",
       "   Home_Perc_Pro_Bowl  Away_Perc_Pro_Bowl  Home_Year  Away_Year  \n",
       "0            0.094340            0.056604     2019.0     2019.0  \n",
       "1            0.113208            0.037736     2019.0     2019.0  \n",
       "2            0.056604            0.000000     2019.0     2019.0  \n",
       "3            0.075472            0.056604     2019.0     2019.0  \n",
       "4            0.000000            0.056604     2019.0     2019.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview dataset\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM modeled_stats\n",
    "\"\"\"\n",
    "\n",
    "#make dataframe\n",
    "data = pd.read_sql_query(query, conn)\n",
    "\n",
    "#preview\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading raw data\n",
    "conn_raw = sqlite3.connect('NFL_Stats.db')\n",
    "c_2 = conn_raw.cursor()\n",
    "\n",
    "query_2 = \"\"\"\n",
    "SELECT * \n",
    "FROM stats_2019\n",
    "\"\"\"\n",
    "query_3 = \"\"\"\n",
    "SELECT * \n",
    "FROM stats_2020\n",
    "\"\"\"\n",
    "#make dataframe\n",
    "year_1 = pd.read_sql_query(query_2, conn_raw)\n",
    "year_2 = pd.read_sql_query(query_2, conn_raw)\n",
    "\n",
    "raw_data = pd.concat([year_1,year_2])\n",
    "raw_data = raw_data.drop(['index','Penalties', 'Opp_Name', 'Superbowl_Win','Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('final_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "nfl_model = model_from_json(loaded_model_json)\n",
    "\n",
    "#add weights\n",
    "nfl_model.load_weights(\"final_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Table(Week_Dict, Week):\n",
    "    columns = raw_data.columns.drop('Team_Name')\n",
    "    df = pd.DataFrame()\n",
    "    for x,y in enumerate(Week_Dict.items()):\n",
    "        Week = Week\n",
    "        Game = 'Week_'+str(Week)+'_'+y[1]\n",
    "        df.loc[Game, 'Home_Team'] = y[1]\n",
    "        df.loc[Game, 'Away_Team'] = y[0]\n",
    "        if raw_data.loc[(raw_data['Team_Name'] == y[1]) & (raw_data['Week_Of_Szn'] == Week)]['Win'].sum() == 0.0:\n",
    "            df.loc[Game, 'Winner'] = 'Away'\n",
    "        else:\n",
    "            df.loc[Game, 'Winner'] = 'Home'\n",
    "        for column in columns:\n",
    "            df.loc[Game, 'Home_'+column] = raw_data.loc[(raw_data['Team_Name'] == y[1]) &\n",
    "                                                   (raw_data['Week_Of_Szn'] <= Week)][column].mean()\n",
    "            df.loc[Game, 'Away_'+column] = raw_data.loc[(raw_data['Team_Name'] == y[0]) & \n",
    "                                                              (raw_data['Week_Of_Szn'] <= Week)][column].mean()\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'd like to create a function in which you can input the two team names, week, and year you're interested in and recieve a prediction! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(Home_Team, Away_Team, Year, Week):\n",
    "    #features from boruta \n",
    "    feats = ['Away_Pts_Scored',\n",
    "     'Home_Pts_Al',\n",
    "     'Away_Pts_Al',\n",
    "     'Home_TDs',\n",
    "     'Home_Rush_Plys_Al',\n",
    "     'Away_Rush_Plys_Al',\n",
    "     'Away_PAT_Att',\n",
    "     'Away_Yds_Pass_Al',\n",
    "     'Home_Pass_Plys_Al']\n",
    "\n",
    "    #preprocessing\n",
    "    Dummy = pd.get_dummies(data, columns=['Winner'])\n",
    "    \n",
    "    first = Dummy.loc[(Dummy['Home_Year'] == Year) & (Dummy['Home_Week'] < Week)]\n",
    "    second = Dummy.loc[(Dummy['Home_Year'] < Year)]\n",
    "    final = pd.concat([first, second])\n",
    "    \n",
    "    #deal with missing data \n",
    "    final = final.fillna(final.mean())\n",
    "    \n",
    "    #train test split\n",
    "    X = final[feats]\n",
    "    y = final.Winner_Home\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, test_size=.2) \n",
    "    \n",
    "    #standard scaling\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #model compilation\n",
    "\n",
    "    nfl_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #fit\n",
    "    nfl_model.fit(X_train, y_train,epochs=50, batch_size=16, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    #evaluate\n",
    "    y_pred = nfl_model.predict(X_test)\n",
    "    score = nfl_model.evaluate(X_test, y_test,verbose=1)\n",
    "    print('\\n''The accuracy of the current model is:',score[1])\n",
    "\n",
    "    ####predict \n",
    "    Week_Pred = {Away_Team : Home_Team}\n",
    "    pred_line = Get_Table(Week_Pred, Week)\n",
    "    pred_dummies = pd.get_dummies(pred_line, columns=['Winner'])\n",
    "    pred_final = pred_dummies[feats]\n",
    "\n",
    "    final_pred = nfl_model.predict_proba(pred_final)\n",
    "    \n",
    "    return print(\"The chance that the\", Home_Team, \"win is:\", (final_pred[0][0]*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 0s 753us/step - loss: 0.5586 - acc: 0.7500 - val_loss: 0.5248 - val_acc: 0.7143\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.5269 - acc: 0.7597 - val_loss: 0.5264 - val_acc: 0.7013\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.5138 - acc: 0.7760 - val_loss: 0.5284 - val_acc: 0.7013\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 132us/step - loss: 0.5475 - acc: 0.7435 - val_loss: 0.5237 - val_acc: 0.7013\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 124us/step - loss: 0.5005 - acc: 0.7825 - val_loss: 0.5176 - val_acc: 0.6883\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.5304 - acc: 0.7597 - val_loss: 0.5137 - val_acc: 0.6753\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 114us/step - loss: 0.5262 - acc: 0.7532 - val_loss: 0.5173 - val_acc: 0.6883\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 122us/step - loss: 0.5419 - acc: 0.7500 - val_loss: 0.5195 - val_acc: 0.6883\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 119us/step - loss: 0.5246 - acc: 0.7630 - val_loss: 0.5270 - val_acc: 0.6883\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.5125 - acc: 0.7760 - val_loss: 0.5294 - val_acc: 0.6883\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 122us/step - loss: 0.5063 - acc: 0.7565 - val_loss: 0.5291 - val_acc: 0.6883\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.5159 - acc: 0.7662 - val_loss: 0.5234 - val_acc: 0.6883\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 120us/step - loss: 0.5108 - acc: 0.7955 - val_loss: 0.5179 - val_acc: 0.6753\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 132us/step - loss: 0.5178 - acc: 0.7565 - val_loss: 0.5208 - val_acc: 0.6753\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 129us/step - loss: 0.5228 - acc: 0.7532 - val_loss: 0.5262 - val_acc: 0.6883\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 136us/step - loss: 0.4864 - acc: 0.7922 - val_loss: 0.5168 - val_acc: 0.6753\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 151us/step - loss: 0.5017 - acc: 0.7565 - val_loss: 0.5134 - val_acc: 0.6753\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.5107 - acc: 0.7695 - val_loss: 0.5185 - val_acc: 0.6753\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.5026 - acc: 0.7890 - val_loss: 0.5230 - val_acc: 0.6753\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.5054 - acc: 0.7565 - val_loss: 0.5187 - val_acc: 0.6753\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.5131 - acc: 0.7532 - val_loss: 0.5187 - val_acc: 0.6753\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 124us/step - loss: 0.5082 - acc: 0.7630 - val_loss: 0.5263 - val_acc: 0.6753\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 121us/step - loss: 0.4819 - acc: 0.7792 - val_loss: 0.5194 - val_acc: 0.6753\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 140us/step - loss: 0.5163 - acc: 0.7532 - val_loss: 0.5189 - val_acc: 0.6753\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.4789 - acc: 0.7825 - val_loss: 0.5139 - val_acc: 0.6883\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.5039 - acc: 0.7532 - val_loss: 0.5119 - val_acc: 0.7013\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 146us/step - loss: 0.4878 - acc: 0.7825 - val_loss: 0.5182 - val_acc: 0.6753\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 132us/step - loss: 0.4842 - acc: 0.7760 - val_loss: 0.5256 - val_acc: 0.6753\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 139us/step - loss: 0.4741 - acc: 0.7890 - val_loss: 0.5205 - val_acc: 0.6883\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 132us/step - loss: 0.5061 - acc: 0.7727 - val_loss: 0.5212 - val_acc: 0.6883\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.4899 - acc: 0.7727 - val_loss: 0.5183 - val_acc: 0.7013\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 132us/step - loss: 0.4652 - acc: 0.7695 - val_loss: 0.5178 - val_acc: 0.7013\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 134us/step - loss: 0.4838 - acc: 0.7792 - val_loss: 0.5242 - val_acc: 0.6753\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 135us/step - loss: 0.4893 - acc: 0.7792 - val_loss: 0.5200 - val_acc: 0.7013\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 129us/step - loss: 0.4638 - acc: 0.7727 - val_loss: 0.5244 - val_acc: 0.7013\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 115us/step - loss: 0.4706 - acc: 0.7922 - val_loss: 0.5218 - val_acc: 0.7143\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 98us/step - loss: 0.4797 - acc: 0.7890 - val_loss: 0.5237 - val_acc: 0.7143\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 90us/step - loss: 0.4715 - acc: 0.7857 - val_loss: 0.5317 - val_acc: 0.6753\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.4514 - acc: 0.8084 - val_loss: 0.5255 - val_acc: 0.7143\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 92us/step - loss: 0.4638 - acc: 0.7792 - val_loss: 0.5282 - val_acc: 0.7013\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 90us/step - loss: 0.4683 - acc: 0.7890 - val_loss: 0.5247 - val_acc: 0.7143\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 89us/step - loss: 0.4622 - acc: 0.7630 - val_loss: 0.5219 - val_acc: 0.7143\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 89us/step - loss: 0.4174 - acc: 0.8214 - val_loss: 0.5269 - val_acc: 0.7143\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 89us/step - loss: 0.4975 - acc: 0.7760 - val_loss: 0.5288 - val_acc: 0.7143\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.4779 - acc: 0.7695 - val_loss: 0.5326 - val_acc: 0.7013\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 90us/step - loss: 0.4738 - acc: 0.7727 - val_loss: 0.5499 - val_acc: 0.6623\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.4366 - acc: 0.7987 - val_loss: 0.5416 - val_acc: 0.7013\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 114us/step - loss: 0.4591 - acc: 0.7857 - val_loss: 0.5311 - val_acc: 0.7273\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 129us/step - loss: 0.4808 - acc: 0.7695 - val_loss: 0.5320 - val_acc: 0.7143\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 116us/step - loss: 0.4745 - acc: 0.8247 - val_loss: 0.5410 - val_acc: 0.6883\n",
      "77/77 [==============================] - 0s 55us/step\n",
      "\n",
      "The accuracy of the current model is: 0.6883116921821197\n",
      "The chance that the Redskins win is: 29.00029420852661 %\n"
     ]
    }
   ],
   "source": [
    "Predict('Redskins','Giants', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Win(Home_Team, Away_Team, Year, Week):\n",
    "    \n",
    "    #features from boruta \n",
    "    #First I've got to get dummy values for \n",
    "    NFL_Dummies = pd.get_dummies(data, columns=['Winner'])\n",
    "    NFL_Dummies = NFL_Dummies.fillna(NFL_Dummies.mean())\n",
    "\n",
    "    X = NFL_Dummies.drop(['Winner_Home','Winner_Away','Home_Team','Away_Team','Home_Win','Away_Win'], axis=1)\n",
    "    y = NFL_Dummies.Winner_Home\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, test_size=.2)\n",
    "    \n",
    "    #boruta\n",
    "    from boruta import BorutaPy\n",
    "\n",
    "    ###initialize Boruta\n",
    "    forest = RandomForestRegressor(\n",
    "       n_jobs = -1, \n",
    "       max_depth = 5\n",
    "    )\n",
    "\n",
    "    boruta = BorutaPy(\n",
    "       estimator = forest, \n",
    "       n_estimators = 50,\n",
    "       max_iter = 200 # number of trials to perform\n",
    "    )\n",
    "\n",
    "    ### fit Boruta (it accepts np.array, not pd.DataFrame)\n",
    "    boruta.fit(np.array(X), np.array(y))\n",
    "\n",
    "    ### print results\n",
    "\n",
    "    green_area = X.columns[boruta.support_].to_list()\n",
    "    blue_area = X.columns[boruta.support_weak_].to_list()\n",
    "    feats = green_area + blue_area\n",
    "    print('The features used in this model were:', feats)\n",
    "\n",
    "    #preprocessing\n",
    "    Dummy = pd.get_dummies(data, columns=['Winner'])\n",
    "    \n",
    "    first = Dummy.loc[(Dummy['Home_Year'] == Year) & (Dummy['Home_Week'] < Week)]\n",
    "    second = Dummy.loc[(Dummy['Home_Year'] < Year)]\n",
    "    final = pd.concat([first, second])\n",
    "    \n",
    "    #deal with missing data \n",
    "    final = final.fillna(final.mean())\n",
    "    \n",
    "    #train test split\n",
    "    X = final[feats]\n",
    "    y = final.Winner_Home\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, test_size=.2) \n",
    "    \n",
    "    np.random.seed(8)\n",
    "\n",
    "    # CNN model \n",
    "\n",
    "    model_1 = Sequential()\n",
    "\n",
    "    model_1.add(Dropout(.2, input_shape=(len(feats),)))\n",
    "\n",
    "    model_1.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model_1.add(Dense(56, activation='relu'))\n",
    "\n",
    "    model_1.add(Dense(40, activation='relu'))\n",
    "\n",
    "    model_1.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model_1.add(Dropout(.3))\n",
    "\n",
    "    model_1.add(Dense(8, activation='relu'))\n",
    "\n",
    "    model_1.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #standard scaling\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #model compilation\n",
    "\n",
    "    model_1.compile(loss='binary_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    #fit\n",
    "    model_1.fit(X_train, y_train,epochs=50, batch_size=16, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    #evaluate\n",
    "    y_pred = model_1.predict(X_test)\n",
    "    score = model_1.evaluate(X_test, y_test,verbose=1)\n",
    "    print('\\n''The accuracy of the current model is:',score[1])\n",
    "\n",
    "    ####predict \n",
    "    Week_Pred = {Away_Team : Home_Team}\n",
    "    pred_line = Get_Table(Week_Pred, Week)\n",
    "    pred_dummies = pd.get_dummies(pred_line, columns=['Winner'])\n",
    "    pred_final = pred_dummies[feats]\n",
    "\n",
    "    final_pred = model_1.predict_proba(pred_final)\n",
    "    \n",
    "    return print(\"The chance that the\", Home_Team, \"win is:\", (final_pred[0][0]*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used in this model were: ['Home_Pts_Scored', 'Away_Pts_Scored', 'Home_Pts_Al', 'Away_Pts_Al', 'Home_TDs', 'Away_Second_Al', 'Home_Rush_Plys_Al', 'Away_Rush_Plys_Al', 'Home_Pass_Att', 'Away_INTs', 'Home_Sacks_Gm', 'Home_PAT_Att', 'Away_PAT_Att', 'Away_Pass_Plys_Al']\n",
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 0s 978us/step - loss: 0.6773 - acc: 0.4870 - val_loss: 0.6633 - val_acc: 0.6234\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.6682 - acc: 0.5714 - val_loss: 0.6601 - val_acc: 0.6364\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.6521 - acc: 0.5909 - val_loss: 0.6524 - val_acc: 0.6234\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.6488 - acc: 0.6201 - val_loss: 0.6477 - val_acc: 0.7013\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.6547 - acc: 0.5974 - val_loss: 0.6391 - val_acc: 0.7013\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.6478 - acc: 0.6396 - val_loss: 0.6323 - val_acc: 0.6883\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 136us/step - loss: 0.6436 - acc: 0.6266 - val_loss: 0.6227 - val_acc: 0.7013\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 137us/step - loss: 0.6419 - acc: 0.6656 - val_loss: 0.6139 - val_acc: 0.7013\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.6225 - acc: 0.6883 - val_loss: 0.6081 - val_acc: 0.7013\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.6191 - acc: 0.6981 - val_loss: 0.6000 - val_acc: 0.7013\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.6090 - acc: 0.6916 - val_loss: 0.5924 - val_acc: 0.6883\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 137us/step - loss: 0.6081 - acc: 0.6948 - val_loss: 0.5857 - val_acc: 0.6753\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 123us/step - loss: 0.5979 - acc: 0.7240 - val_loss: 0.5774 - val_acc: 0.6883\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 140us/step - loss: 0.5840 - acc: 0.7143 - val_loss: 0.5738 - val_acc: 0.6883\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.5909 - acc: 0.7305 - val_loss: 0.5698 - val_acc: 0.6883\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 137us/step - loss: 0.5855 - acc: 0.7045 - val_loss: 0.5636 - val_acc: 0.6883\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 134us/step - loss: 0.5777 - acc: 0.7403 - val_loss: 0.5602 - val_acc: 0.7013\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.5623 - acc: 0.7468 - val_loss: 0.5605 - val_acc: 0.7013\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 149us/step - loss: 0.5674 - acc: 0.7468 - val_loss: 0.5549 - val_acc: 0.7143\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.5656 - acc: 0.7403 - val_loss: 0.5547 - val_acc: 0.7013\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.5527 - acc: 0.7565 - val_loss: 0.5552 - val_acc: 0.7143\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 153us/step - loss: 0.5475 - acc: 0.7597 - val_loss: 0.5497 - val_acc: 0.7143\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.5514 - acc: 0.7468 - val_loss: 0.5427 - val_acc: 0.6883\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.5515 - acc: 0.7532 - val_loss: 0.5384 - val_acc: 0.7143\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 135us/step - loss: 0.5401 - acc: 0.7857 - val_loss: 0.5423 - val_acc: 0.6753\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.5391 - acc: 0.7403 - val_loss: 0.5377 - val_acc: 0.7013\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 137us/step - loss: 0.5344 - acc: 0.7597 - val_loss: 0.5409 - val_acc: 0.6753\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.5390 - acc: 0.7565 - val_loss: 0.5439 - val_acc: 0.6883\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 136us/step - loss: 0.5313 - acc: 0.7890 - val_loss: 0.5401 - val_acc: 0.6753\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.5343 - acc: 0.7597 - val_loss: 0.5384 - val_acc: 0.6883\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 132us/step - loss: 0.5331 - acc: 0.7662 - val_loss: 0.5348 - val_acc: 0.7013\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.5219 - acc: 0.7532 - val_loss: 0.5327 - val_acc: 0.7273\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.5224 - acc: 0.7760 - val_loss: 0.5290 - val_acc: 0.7273\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 139us/step - loss: 0.5008 - acc: 0.7792 - val_loss: 0.5279 - val_acc: 0.7273\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 140us/step - loss: 0.5093 - acc: 0.7597 - val_loss: 0.5295 - val_acc: 0.7273\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 137us/step - loss: 0.5224 - acc: 0.7532 - val_loss: 0.5328 - val_acc: 0.7013\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 121us/step - loss: 0.4889 - acc: 0.7597 - val_loss: 0.5286 - val_acc: 0.7273\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 100us/step - loss: 0.5048 - acc: 0.7662 - val_loss: 0.5296 - val_acc: 0.7143\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 128us/step - loss: 0.5006 - acc: 0.7857 - val_loss: 0.5198 - val_acc: 0.7273\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.4897 - acc: 0.7662 - val_loss: 0.5241 - val_acc: 0.7273\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 114us/step - loss: 0.4782 - acc: 0.7695 - val_loss: 0.5243 - val_acc: 0.7273\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 130us/step - loss: 0.4963 - acc: 0.7695 - val_loss: 0.5200 - val_acc: 0.7273\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 124us/step - loss: 0.5016 - acc: 0.7597 - val_loss: 0.5193 - val_acc: 0.7273\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 124us/step - loss: 0.4873 - acc: 0.7825 - val_loss: 0.5159 - val_acc: 0.7273\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 135us/step - loss: 0.4806 - acc: 0.7597 - val_loss: 0.5202 - val_acc: 0.7273\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.4856 - acc: 0.7695 - val_loss: 0.5239 - val_acc: 0.7273\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 128us/step - loss: 0.4722 - acc: 0.7825 - val_loss: 0.5284 - val_acc: 0.7273\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 126us/step - loss: 0.4857 - acc: 0.7532 - val_loss: 0.5251 - val_acc: 0.7273\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 118us/step - loss: 0.4903 - acc: 0.7727 - val_loss: 0.5277 - val_acc: 0.7273\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.4826 - acc: 0.8052 - val_loss: 0.5244 - val_acc: 0.7273\n",
      "77/77 [==============================] - 0s 44us/step\n",
      "\n",
      "The accuracy of the current model is: 0.7272727303690725\n",
      "The chance that the Redskins win is: 10.947814583778381 %\n"
     ]
    }
   ],
   "source": [
    "Predict_Win('Redskins','Giants',2020,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used in this model were: ['Home_Pts_Scored', 'Away_Pts_Scored', 'Home_Pts_Al', 'Away_Pts_Al', 'Away_Second_Al', 'Home_Rush_Plys_Al', 'Away_Rush_Plys_Al', 'Away_Pass_Plys_Al', 'Away_INTs', 'Home_Sacks_Gm', 'Home_PAT_Att', 'Away_PAT_Att', 'Home_TDs']\n",
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.7251 - acc: 0.4708 - val_loss: 0.6941 - val_acc: 0.5195\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 105us/step - loss: 0.7032 - acc: 0.5422 - val_loss: 0.6832 - val_acc: 0.6234\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 104us/step - loss: 0.6841 - acc: 0.5617 - val_loss: 0.6742 - val_acc: 0.6494\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 94us/step - loss: 0.6694 - acc: 0.6266 - val_loss: 0.6658 - val_acc: 0.7143\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.6659 - acc: 0.6266 - val_loss: 0.6557 - val_acc: 0.7143\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.6584 - acc: 0.6526 - val_loss: 0.6456 - val_acc: 0.7662\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.6486 - acc: 0.6526 - val_loss: 0.6349 - val_acc: 0.7273\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.6348 - acc: 0.6721 - val_loss: 0.6248 - val_acc: 0.7403\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.6208 - acc: 0.6916 - val_loss: 0.6155 - val_acc: 0.7273\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 95us/step - loss: 0.6088 - acc: 0.7013 - val_loss: 0.6063 - val_acc: 0.7273\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 128us/step - loss: 0.6001 - acc: 0.7143 - val_loss: 0.5941 - val_acc: 0.7662\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 110us/step - loss: 0.5950 - acc: 0.7175 - val_loss: 0.5851 - val_acc: 0.7662\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 95us/step - loss: 0.5867 - acc: 0.7045 - val_loss: 0.5744 - val_acc: 0.7532\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 97us/step - loss: 0.5650 - acc: 0.7208 - val_loss: 0.5665 - val_acc: 0.7532\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.5657 - acc: 0.7403 - val_loss: 0.5591 - val_acc: 0.7532\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 93us/step - loss: 0.5626 - acc: 0.7370 - val_loss: 0.5520 - val_acc: 0.7532\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 94us/step - loss: 0.5546 - acc: 0.7565 - val_loss: 0.5443 - val_acc: 0.7532\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.5404 - acc: 0.7662 - val_loss: 0.5417 - val_acc: 0.7532\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.5425 - acc: 0.7370 - val_loss: 0.5359 - val_acc: 0.7532\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 94us/step - loss: 0.5189 - acc: 0.7565 - val_loss: 0.5304 - val_acc: 0.7532\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 94us/step - loss: 0.5054 - acc: 0.7662 - val_loss: 0.5287 - val_acc: 0.7532\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 98us/step - loss: 0.5339 - acc: 0.7435 - val_loss: 0.5242 - val_acc: 0.7532\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 104us/step - loss: 0.5198 - acc: 0.7597 - val_loss: 0.5183 - val_acc: 0.7403\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 153us/step - loss: 0.5126 - acc: 0.7403 - val_loss: 0.5145 - val_acc: 0.7403\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 151us/step - loss: 0.4935 - acc: 0.7727 - val_loss: 0.5142 - val_acc: 0.7532\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 100us/step - loss: 0.5292 - acc: 0.7435 - val_loss: 0.5126 - val_acc: 0.7532\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 92us/step - loss: 0.4949 - acc: 0.8019 - val_loss: 0.5117 - val_acc: 0.7662\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.4929 - acc: 0.7695 - val_loss: 0.5133 - val_acc: 0.7662\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 90us/step - loss: 0.5109 - acc: 0.7532 - val_loss: 0.5099 - val_acc: 0.7662\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 92us/step - loss: 0.5158 - acc: 0.7403 - val_loss: 0.5086 - val_acc: 0.7662\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 93us/step - loss: 0.4934 - acc: 0.7987 - val_loss: 0.5065 - val_acc: 0.7532\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.4920 - acc: 0.7630 - val_loss: 0.5082 - val_acc: 0.7662\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 91us/step - loss: 0.4817 - acc: 0.7857 - val_loss: 0.5053 - val_acc: 0.7662\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 95us/step - loss: 0.4955 - acc: 0.7532 - val_loss: 0.5040 - val_acc: 0.7532\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 102us/step - loss: 0.5106 - acc: 0.7500 - val_loss: 0.5070 - val_acc: 0.7532\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 148us/step - loss: 0.4893 - acc: 0.7500 - val_loss: 0.5077 - val_acc: 0.7532\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 145us/step - loss: 0.4651 - acc: 0.7760 - val_loss: 0.5060 - val_acc: 0.7532\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 151us/step - loss: 0.4687 - acc: 0.7890 - val_loss: 0.5030 - val_acc: 0.7532\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.4882 - acc: 0.7468 - val_loss: 0.5014 - val_acc: 0.7532\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.4750 - acc: 0.7825 - val_loss: 0.4995 - val_acc: 0.7662\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 97us/step - loss: 0.4859 - acc: 0.7857 - val_loss: 0.5018 - val_acc: 0.7792\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 100us/step - loss: 0.4765 - acc: 0.7792 - val_loss: 0.5024 - val_acc: 0.7792\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 104us/step - loss: 0.4818 - acc: 0.7662 - val_loss: 0.4998 - val_acc: 0.7792\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 102us/step - loss: 0.4755 - acc: 0.7727 - val_loss: 0.4995 - val_acc: 0.7792\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 106us/step - loss: 0.4759 - acc: 0.7695 - val_loss: 0.5033 - val_acc: 0.7662\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 101us/step - loss: 0.4842 - acc: 0.7630 - val_loss: 0.5046 - val_acc: 0.7662\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 92us/step - loss: 0.4653 - acc: 0.7792 - val_loss: 0.5070 - val_acc: 0.7532\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 92us/step - loss: 0.4639 - acc: 0.7857 - val_loss: 0.5030 - val_acc: 0.7792\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 93us/step - loss: 0.4657 - acc: 0.7760 - val_loss: 0.5036 - val_acc: 0.7662\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 103us/step - loss: 0.4582 - acc: 0.7597 - val_loss: 0.5075 - val_acc: 0.7662\n",
      "77/77 [==============================] - 0s 41us/step\n",
      "\n",
      "The accuracy of the current model is: 0.7662337701041977\n",
      "The chance that the Cowboys win is: 97.89743423461914 %\n"
     ]
    }
   ],
   "source": [
    "Predict_Win('Cowboys','Steelers', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used in this model were: ['Home_Pts_Scored', 'Away_Pts_Scored', 'Home_Pts_Al', 'Away_Pts_Al', 'Away_Second_Al', 'Home_Rush_Plys_Al', 'Away_Rush_Plys_Al', 'Away_Pass_Plys_Al', 'Away_INTs', 'Home_Sacks_Gm', 'Home_PAT_Att', 'Away_PAT_Att', 'Home_TDs']\n",
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 0.7251 - acc: 0.4708 - val_loss: 0.6941 - val_acc: 0.5195\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 216us/step - loss: 0.7032 - acc: 0.5422 - val_loss: 0.6832 - val_acc: 0.6234\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 167us/step - loss: 0.6842 - acc: 0.5617 - val_loss: 0.6744 - val_acc: 0.6494\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 125us/step - loss: 0.6695 - acc: 0.6266 - val_loss: 0.6659 - val_acc: 0.7143\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.6660 - acc: 0.6299 - val_loss: 0.6558 - val_acc: 0.7143\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.6586 - acc: 0.6526 - val_loss: 0.6458 - val_acc: 0.7532\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 162us/step - loss: 0.6487 - acc: 0.6558 - val_loss: 0.6350 - val_acc: 0.7403\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 149us/step - loss: 0.6349 - acc: 0.6688 - val_loss: 0.6249 - val_acc: 0.7403\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 135us/step - loss: 0.6209 - acc: 0.6916 - val_loss: 0.6156 - val_acc: 0.7273\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.6089 - acc: 0.7013 - val_loss: 0.6064 - val_acc: 0.7143\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 169us/step - loss: 0.6003 - acc: 0.7143 - val_loss: 0.5941 - val_acc: 0.7662\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 243us/step - loss: 0.5951 - acc: 0.7208 - val_loss: 0.5851 - val_acc: 0.7662\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 593us/step - loss: 0.5867 - acc: 0.7045 - val_loss: 0.5743 - val_acc: 0.7532\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 244us/step - loss: 0.5650 - acc: 0.7208 - val_loss: 0.5665 - val_acc: 0.7532\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 200us/step - loss: 0.5657 - acc: 0.7403 - val_loss: 0.5591 - val_acc: 0.7532\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 189us/step - loss: 0.5626 - acc: 0.7370 - val_loss: 0.5520 - val_acc: 0.7532\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 165us/step - loss: 0.5546 - acc: 0.7565 - val_loss: 0.5444 - val_acc: 0.7532\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 150us/step - loss: 0.5404 - acc: 0.7662 - val_loss: 0.5419 - val_acc: 0.7403\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 206us/step - loss: 0.5423 - acc: 0.7435 - val_loss: 0.5359 - val_acc: 0.7532\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 212us/step - loss: 0.5190 - acc: 0.7597 - val_loss: 0.5304 - val_acc: 0.7532\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 202us/step - loss: 0.5055 - acc: 0.7662 - val_loss: 0.5287 - val_acc: 0.7532\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 168us/step - loss: 0.5340 - acc: 0.7435 - val_loss: 0.5243 - val_acc: 0.7532\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 155us/step - loss: 0.5197 - acc: 0.7565 - val_loss: 0.5184 - val_acc: 0.7403\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 156us/step - loss: 0.5126 - acc: 0.7370 - val_loss: 0.5146 - val_acc: 0.7403\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 163us/step - loss: 0.4936 - acc: 0.7727 - val_loss: 0.5142 - val_acc: 0.7532\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 172us/step - loss: 0.5290 - acc: 0.7435 - val_loss: 0.5124 - val_acc: 0.7532\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 182us/step - loss: 0.4949 - acc: 0.7987 - val_loss: 0.5118 - val_acc: 0.7662\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 175us/step - loss: 0.4929 - acc: 0.7695 - val_loss: 0.5134 - val_acc: 0.7532\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 144us/step - loss: 0.5108 - acc: 0.7532 - val_loss: 0.5100 - val_acc: 0.7662\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 149us/step - loss: 0.5156 - acc: 0.7403 - val_loss: 0.5086 - val_acc: 0.7662\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 135us/step - loss: 0.4934 - acc: 0.7987 - val_loss: 0.5065 - val_acc: 0.7532\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 148us/step - loss: 0.4919 - acc: 0.7630 - val_loss: 0.5082 - val_acc: 0.7662\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 165us/step - loss: 0.4816 - acc: 0.7857 - val_loss: 0.5052 - val_acc: 0.7662\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 174us/step - loss: 0.4953 - acc: 0.7532 - val_loss: 0.5038 - val_acc: 0.7532\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 162us/step - loss: 0.5103 - acc: 0.7500 - val_loss: 0.5068 - val_acc: 0.7532\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 149us/step - loss: 0.4890 - acc: 0.7468 - val_loss: 0.5074 - val_acc: 0.7532\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 134us/step - loss: 0.4649 - acc: 0.7760 - val_loss: 0.5059 - val_acc: 0.7532\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 144us/step - loss: 0.4686 - acc: 0.7890 - val_loss: 0.5030 - val_acc: 0.7532\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 123us/step - loss: 0.4881 - acc: 0.7468 - val_loss: 0.5017 - val_acc: 0.7532\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.4748 - acc: 0.7792 - val_loss: 0.4997 - val_acc: 0.7662\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 123us/step - loss: 0.4859 - acc: 0.7857 - val_loss: 0.5018 - val_acc: 0.7792\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.4765 - acc: 0.7792 - val_loss: 0.5024 - val_acc: 0.7792\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 134us/step - loss: 0.4816 - acc: 0.7662 - val_loss: 0.5000 - val_acc: 0.7792\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 136us/step - loss: 0.4755 - acc: 0.7727 - val_loss: 0.4995 - val_acc: 0.7792\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 139us/step - loss: 0.4760 - acc: 0.7695 - val_loss: 0.5034 - val_acc: 0.7662\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 120us/step - loss: 0.4841 - acc: 0.7630 - val_loss: 0.5046 - val_acc: 0.7662\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.4654 - acc: 0.7760 - val_loss: 0.5068 - val_acc: 0.7532\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 172us/step - loss: 0.4639 - acc: 0.7857 - val_loss: 0.5034 - val_acc: 0.7792\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 218us/step - loss: 0.4654 - acc: 0.7760 - val_loss: 0.5036 - val_acc: 0.7792\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 203us/step - loss: 0.4582 - acc: 0.7597 - val_loss: 0.5074 - val_acc: 0.7662\n",
      "77/77 [==============================] - 0s 61us/step\n",
      "\n",
      "The accuracy of the current model is: 0.7662337701041977\n",
      "The chance that the 49ers win is: 99.39602613449097 %\n"
     ]
    }
   ],
   "source": [
    "Predict_Win('49ers','Packers', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 0.4649 - acc: 0.7662 - val_loss: 0.5335 - val_acc: 0.7143\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 141us/step - loss: 0.4719 - acc: 0.7792 - val_loss: 0.5290 - val_acc: 0.7273\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 130us/step - loss: 0.4645 - acc: 0.8052 - val_loss: 0.5312 - val_acc: 0.7273\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 152us/step - loss: 0.4585 - acc: 0.7695 - val_loss: 0.5267 - val_acc: 0.7273\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.4455 - acc: 0.7662 - val_loss: 0.5327 - val_acc: 0.7143\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 127us/step - loss: 0.4422 - acc: 0.8052 - val_loss: 0.5221 - val_acc: 0.7273\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.4539 - acc: 0.7792 - val_loss: 0.5225 - val_acc: 0.7273\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.4514 - acc: 0.7857 - val_loss: 0.5340 - val_acc: 0.7273\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 160us/step - loss: 0.4632 - acc: 0.7890 - val_loss: 0.5299 - val_acc: 0.7273\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 147us/step - loss: 0.4563 - acc: 0.7890 - val_loss: 0.5178 - val_acc: 0.7143\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.4725 - acc: 0.7792 - val_loss: 0.5238 - val_acc: 0.7273\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 140us/step - loss: 0.4530 - acc: 0.7825 - val_loss: 0.5194 - val_acc: 0.7143\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 155us/step - loss: 0.4676 - acc: 0.7890 - val_loss: 0.5312 - val_acc: 0.7273\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 146us/step - loss: 0.4479 - acc: 0.8052 - val_loss: 0.5292 - val_acc: 0.7273\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 135us/step - loss: 0.4753 - acc: 0.7565 - val_loss: 0.5311 - val_acc: 0.7273\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 139us/step - loss: 0.4719 - acc: 0.7760 - val_loss: 0.5215 - val_acc: 0.7273\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 133us/step - loss: 0.4816 - acc: 0.7662 - val_loss: 0.5246 - val_acc: 0.7273\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 108us/step - loss: 0.4628 - acc: 0.7987 - val_loss: 0.5229 - val_acc: 0.7273\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 176us/step - loss: 0.4370 - acc: 0.7987 - val_loss: 0.5251 - val_acc: 0.7273\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 206us/step - loss: 0.4496 - acc: 0.7955 - val_loss: 0.5335 - val_acc: 0.7273\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 191us/step - loss: 0.4463 - acc: 0.7760 - val_loss: 0.5257 - val_acc: 0.7273\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 177us/step - loss: 0.4505 - acc: 0.7890 - val_loss: 0.5282 - val_acc: 0.7273\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 185us/step - loss: 0.4593 - acc: 0.8117 - val_loss: 0.5343 - val_acc: 0.7143\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 167us/step - loss: 0.4475 - acc: 0.8149 - val_loss: 0.5410 - val_acc: 0.7143\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 168us/step - loss: 0.4592 - acc: 0.7695 - val_loss: 0.5336 - val_acc: 0.7143\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 151us/step - loss: 0.4495 - acc: 0.7922 - val_loss: 0.5322 - val_acc: 0.7013\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 163us/step - loss: 0.4285 - acc: 0.7955 - val_loss: 0.5312 - val_acc: 0.7013\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 124us/step - loss: 0.4088 - acc: 0.8214 - val_loss: 0.5256 - val_acc: 0.7143\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 109us/step - loss: 0.4390 - acc: 0.7922 - val_loss: 0.5351 - val_acc: 0.7013\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 169us/step - loss: 0.3959 - acc: 0.8344 - val_loss: 0.5343 - val_acc: 0.7013\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 243us/step - loss: 0.4340 - acc: 0.8019 - val_loss: 0.5280 - val_acc: 0.7143\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 162us/step - loss: 0.4324 - acc: 0.8084 - val_loss: 0.5283 - val_acc: 0.7143\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 166us/step - loss: 0.4407 - acc: 0.7955 - val_loss: 0.5258 - val_acc: 0.7143\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 161us/step - loss: 0.4352 - acc: 0.8019 - val_loss: 0.5212 - val_acc: 0.7143\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 151us/step - loss: 0.4388 - acc: 0.7825 - val_loss: 0.5262 - val_acc: 0.7013\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 150us/step - loss: 0.4565 - acc: 0.7727 - val_loss: 0.5247 - val_acc: 0.7013\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 140us/step - loss: 0.4333 - acc: 0.8019 - val_loss: 0.5236 - val_acc: 0.7143\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 152us/step - loss: 0.4640 - acc: 0.7727 - val_loss: 0.5249 - val_acc: 0.7013\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 162us/step - loss: 0.4585 - acc: 0.7825 - val_loss: 0.5299 - val_acc: 0.7013\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 151us/step - loss: 0.4567 - acc: 0.7890 - val_loss: 0.5410 - val_acc: 0.6883\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 148us/step - loss: 0.4319 - acc: 0.8149 - val_loss: 0.5367 - val_acc: 0.7013\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 156us/step - loss: 0.4074 - acc: 0.8052 - val_loss: 0.5379 - val_acc: 0.7013\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 148us/step - loss: 0.4562 - acc: 0.7695 - val_loss: 0.5291 - val_acc: 0.7013\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 138us/step - loss: 0.4589 - acc: 0.7760 - val_loss: 0.5341 - val_acc: 0.7013\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 131us/step - loss: 0.4453 - acc: 0.7695 - val_loss: 0.5267 - val_acc: 0.7143\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 144us/step - loss: 0.4206 - acc: 0.8052 - val_loss: 0.5304 - val_acc: 0.7143\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 154us/step - loss: 0.4231 - acc: 0.7955 - val_loss: 0.5351 - val_acc: 0.7013\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 149us/step - loss: 0.4289 - acc: 0.7987 - val_loss: 0.5421 - val_acc: 0.7013\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 169us/step - loss: 0.4289 - acc: 0.7857 - val_loss: 0.5474 - val_acc: 0.7013\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.4407 - acc: 0.7987 - val_loss: 0.5484 - val_acc: 0.7013\n",
      "77/77 [==============================] - 0s 39us/step\n",
      "\n",
      "The accuracy of the current model is: 0.7012987051691327\n",
      "The chance that the 49ers win is: 1.528938398109858e-06 %\n"
     ]
    }
   ],
   "source": [
    "Predict('49ers','Packers', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.4251 - acc: 0.7987 - val_loss: 0.5460 - val_acc: 0.7013\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 218us/step - loss: 0.4448 - acc: 0.7792 - val_loss: 0.5361 - val_acc: 0.7013\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 212us/step - loss: 0.4078 - acc: 0.8247 - val_loss: 0.5409 - val_acc: 0.7013\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 216us/step - loss: 0.4438 - acc: 0.7922 - val_loss: 0.5484 - val_acc: 0.7013\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 228us/step - loss: 0.4254 - acc: 0.8117 - val_loss: 0.5323 - val_acc: 0.7013\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 216us/step - loss: 0.4404 - acc: 0.8149 - val_loss: 0.5321 - val_acc: 0.7013\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 205us/step - loss: 0.4482 - acc: 0.8084 - val_loss: 0.5304 - val_acc: 0.7013\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 251us/step - loss: 0.4413 - acc: 0.7857 - val_loss: 0.5345 - val_acc: 0.7013\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 265us/step - loss: 0.4529 - acc: 0.8019 - val_loss: 0.5425 - val_acc: 0.7013\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 189us/step - loss: 0.4211 - acc: 0.8279 - val_loss: 0.5346 - val_acc: 0.7013\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 198us/step - loss: 0.4262 - acc: 0.7987 - val_loss: 0.5427 - val_acc: 0.7013\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 185us/step - loss: 0.4391 - acc: 0.8052 - val_loss: 0.5505 - val_acc: 0.7013\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 173us/step - loss: 0.4361 - acc: 0.8019 - val_loss: 0.5397 - val_acc: 0.7013\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 181us/step - loss: 0.4127 - acc: 0.8214 - val_loss: 0.5372 - val_acc: 0.7013\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 136us/step - loss: 0.4227 - acc: 0.8052 - val_loss: 0.5347 - val_acc: 0.7013\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 155us/step - loss: 0.4213 - acc: 0.8019 - val_loss: 0.5354 - val_acc: 0.7013\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 142us/step - loss: 0.4033 - acc: 0.8182 - val_loss: 0.5379 - val_acc: 0.7013\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 148us/step - loss: 0.4269 - acc: 0.8117 - val_loss: 0.5408 - val_acc: 0.7013\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.4513 - acc: 0.8019 - val_loss: 0.5394 - val_acc: 0.7013\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 159us/step - loss: 0.4327 - acc: 0.7857 - val_loss: 0.5407 - val_acc: 0.7013\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 148us/step - loss: 0.4202 - acc: 0.7987 - val_loss: 0.5382 - val_acc: 0.7013\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 147us/step - loss: 0.4035 - acc: 0.8084 - val_loss: 0.5428 - val_acc: 0.7013\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 143us/step - loss: 0.4014 - acc: 0.8182 - val_loss: 0.5497 - val_acc: 0.6883\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 243us/step - loss: 0.4129 - acc: 0.7922 - val_loss: 0.5536 - val_acc: 0.6883\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 245us/step - loss: 0.4085 - acc: 0.8117 - val_loss: 0.5479 - val_acc: 0.7013\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 197us/step - loss: 0.4141 - acc: 0.8117 - val_loss: 0.5378 - val_acc: 0.6883\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 213us/step - loss: 0.4613 - acc: 0.7857 - val_loss: 0.5388 - val_acc: 0.7013\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 180us/step - loss: 0.4156 - acc: 0.8052 - val_loss: 0.5355 - val_acc: 0.6883\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 186us/step - loss: 0.4041 - acc: 0.8149 - val_loss: 0.5598 - val_acc: 0.6883\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 152us/step - loss: 0.4319 - acc: 0.7987 - val_loss: 0.5568 - val_acc: 0.6883\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 172us/step - loss: 0.4293 - acc: 0.7695 - val_loss: 0.5504 - val_acc: 0.6883\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 179us/step - loss: 0.4428 - acc: 0.8214 - val_loss: 0.5398 - val_acc: 0.7013\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 165us/step - loss: 0.4216 - acc: 0.8019 - val_loss: 0.5342 - val_acc: 0.6753\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 145us/step - loss: 0.4096 - acc: 0.8084 - val_loss: 0.5400 - val_acc: 0.6753\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 145us/step - loss: 0.3915 - acc: 0.8279 - val_loss: 0.5476 - val_acc: 0.6883\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 147us/step - loss: 0.4145 - acc: 0.8019 - val_loss: 0.5380 - val_acc: 0.6753\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 146us/step - loss: 0.4110 - acc: 0.8117 - val_loss: 0.5358 - val_acc: 0.6623\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 153us/step - loss: 0.4201 - acc: 0.8052 - val_loss: 0.5568 - val_acc: 0.6883\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 191us/step - loss: 0.3960 - acc: 0.8149 - val_loss: 0.5478 - val_acc: 0.7013\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 219us/step - loss: 0.3929 - acc: 0.8442 - val_loss: 0.5383 - val_acc: 0.6623\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 324us/step - loss: 0.3936 - acc: 0.8182 - val_loss: 0.5435 - val_acc: 0.6753\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 386us/step - loss: 0.4181 - acc: 0.7922 - val_loss: 0.5515 - val_acc: 0.6883\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 413us/step - loss: 0.4178 - acc: 0.7987 - val_loss: 0.5425 - val_acc: 0.6753\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 310us/step - loss: 0.4195 - acc: 0.8214 - val_loss: 0.5358 - val_acc: 0.6623\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 330us/step - loss: 0.4341 - acc: 0.7955 - val_loss: 0.5456 - val_acc: 0.6753\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 290us/step - loss: 0.4218 - acc: 0.8149 - val_loss: 0.5468 - val_acc: 0.6753\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 310us/step - loss: 0.4039 - acc: 0.7955 - val_loss: 0.5598 - val_acc: 0.7013\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 260us/step - loss: 0.4221 - acc: 0.7987 - val_loss: 0.5449 - val_acc: 0.6753\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 391us/step - loss: 0.4043 - acc: 0.8409 - val_loss: 0.5476 - val_acc: 0.6623\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 278us/step - loss: 0.4222 - acc: 0.8149 - val_loss: 0.5470 - val_acc: 0.6883\n",
      "77/77 [==============================] - 0s 122us/step\n",
      "\n",
      "The accuracy of the current model is: 0.6883116921821197\n",
      "The chance that the Cowboys win is: 1.15007914303078e-07 %\n"
     ]
    }
   ],
   "source": [
    "Predict('Cowboys','Steelers', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used in this model were: ['Home_Pts_Scored', 'Away_Pts_Scored', 'Home_Pts_Al', 'Away_Pts_Al', 'Home_TDs', 'Away_Second_Al', 'Home_Rush_Plys_Al', 'Away_Rush_Plys_Al', 'Away_INTs', 'Home_Sacks_Gm', 'Home_PAT_Att', 'Away_PAT_Att', 'Away_Pass_Plys_Al', 'Home_Pass_Att']\n",
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.6755 - acc: 0.5162 - val_loss: 0.6554 - val_acc: 0.6494\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 250us/step - loss: 0.6659 - acc: 0.5844 - val_loss: 0.6524 - val_acc: 0.6364\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 267us/step - loss: 0.6467 - acc: 0.6299 - val_loss: 0.6423 - val_acc: 0.6883\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 273us/step - loss: 0.6422 - acc: 0.6656 - val_loss: 0.6364 - val_acc: 0.6623\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 324us/step - loss: 0.6414 - acc: 0.6526 - val_loss: 0.6263 - val_acc: 0.6753\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 346us/step - loss: 0.6366 - acc: 0.6591 - val_loss: 0.6194 - val_acc: 0.6753\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 248us/step - loss: 0.6286 - acc: 0.6688 - val_loss: 0.6110 - val_acc: 0.6753\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 272us/step - loss: 0.6164 - acc: 0.7240 - val_loss: 0.6027 - val_acc: 0.7013\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 264us/step - loss: 0.6104 - acc: 0.7240 - val_loss: 0.5964 - val_acc: 0.7013\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 309us/step - loss: 0.6003 - acc: 0.7240 - val_loss: 0.5878 - val_acc: 0.7013\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 309us/step - loss: 0.5919 - acc: 0.7370 - val_loss: 0.5804 - val_acc: 0.7013\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 348us/step - loss: 0.5961 - acc: 0.7273 - val_loss: 0.5745 - val_acc: 0.7013\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 316us/step - loss: 0.5828 - acc: 0.7792 - val_loss: 0.5663 - val_acc: 0.7143\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 272us/step - loss: 0.5586 - acc: 0.7565 - val_loss: 0.5624 - val_acc: 0.7273\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 268us/step - loss: 0.5649 - acc: 0.7565 - val_loss: 0.5582 - val_acc: 0.7143\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 330us/step - loss: 0.5707 - acc: 0.7370 - val_loss: 0.5531 - val_acc: 0.7143\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 288us/step - loss: 0.5607 - acc: 0.7403 - val_loss: 0.5492 - val_acc: 0.7143\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 323us/step - loss: 0.5464 - acc: 0.7760 - val_loss: 0.5465 - val_acc: 0.7143\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 284us/step - loss: 0.5372 - acc: 0.7727 - val_loss: 0.5396 - val_acc: 0.7143\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 293us/step - loss: 0.5306 - acc: 0.7695 - val_loss: 0.5384 - val_acc: 0.7143\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 397us/step - loss: 0.5144 - acc: 0.7857 - val_loss: 0.5404 - val_acc: 0.7143\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 335us/step - loss: 0.5248 - acc: 0.7792 - val_loss: 0.5370 - val_acc: 0.7143\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 344us/step - loss: 0.5296 - acc: 0.7175 - val_loss: 0.5307 - val_acc: 0.7143\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 309us/step - loss: 0.5163 - acc: 0.7792 - val_loss: 0.5244 - val_acc: 0.7013\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 251us/step - loss: 0.5212 - acc: 0.7727 - val_loss: 0.5327 - val_acc: 0.7273\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 274us/step - loss: 0.5017 - acc: 0.7727 - val_loss: 0.5266 - val_acc: 0.7143\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 273us/step - loss: 0.5072 - acc: 0.7955 - val_loss: 0.5287 - val_acc: 0.7403\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 319us/step - loss: 0.5155 - acc: 0.7532 - val_loss: 0.5285 - val_acc: 0.7273\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 290us/step - loss: 0.5006 - acc: 0.7760 - val_loss: 0.5226 - val_acc: 0.7143\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 354us/step - loss: 0.5016 - acc: 0.7597 - val_loss: 0.5226 - val_acc: 0.7143\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 273us/step - loss: 0.5114 - acc: 0.7597 - val_loss: 0.5179 - val_acc: 0.7143\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 312us/step - loss: 0.4853 - acc: 0.7857 - val_loss: 0.5193 - val_acc: 0.7143\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 271us/step - loss: 0.4968 - acc: 0.7662 - val_loss: 0.5160 - val_acc: 0.7143\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 298us/step - loss: 0.4822 - acc: 0.7662 - val_loss: 0.5182 - val_acc: 0.7143\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 295us/step - loss: 0.4848 - acc: 0.7662 - val_loss: 0.5210 - val_acc: 0.7143\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 327us/step - loss: 0.4837 - acc: 0.7695 - val_loss: 0.5194 - val_acc: 0.7143\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 297us/step - loss: 0.4573 - acc: 0.7792 - val_loss: 0.5169 - val_acc: 0.7143\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 267us/step - loss: 0.4816 - acc: 0.8019 - val_loss: 0.5148 - val_acc: 0.7143\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 277us/step - loss: 0.4791 - acc: 0.7500 - val_loss: 0.5107 - val_acc: 0.7403\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 266us/step - loss: 0.4674 - acc: 0.7792 - val_loss: 0.5106 - val_acc: 0.7403\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 269us/step - loss: 0.4483 - acc: 0.7922 - val_loss: 0.5176 - val_acc: 0.7273\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 289us/step - loss: 0.4725 - acc: 0.7825 - val_loss: 0.5146 - val_acc: 0.7403\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 305us/step - loss: 0.4727 - acc: 0.7727 - val_loss: 0.5126 - val_acc: 0.7403\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 305us/step - loss: 0.4526 - acc: 0.8019 - val_loss: 0.5093 - val_acc: 0.7273\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 225us/step - loss: 0.4626 - acc: 0.7760 - val_loss: 0.5143 - val_acc: 0.7273\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 289us/step - loss: 0.4736 - acc: 0.7630 - val_loss: 0.5190 - val_acc: 0.7403\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 291us/step - loss: 0.4486 - acc: 0.7922 - val_loss: 0.5183 - val_acc: 0.7403\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 274us/step - loss: 0.4579 - acc: 0.8052 - val_loss: 0.5170 - val_acc: 0.7273\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 295us/step - loss: 0.4889 - acc: 0.7922 - val_loss: 0.5209 - val_acc: 0.7273\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 231us/step - loss: 0.4774 - acc: 0.7792 - val_loss: 0.5222 - val_acc: 0.7273\n",
      "77/77 [==============================] - 0s 58us/step\n",
      "\n",
      "The accuracy of the current model is: 0.7272727303690725\n",
      "The chance that the Chiefs win is: 0.03943851625081152 %\n"
     ]
    }
   ],
   "source": [
    "Predict_Win('Chiefs','Panthers', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308 samples, validate on 77 samples\n",
      "Epoch 1/50\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 0.4128 - acc: 0.7922 - val_loss: 0.5513 - val_acc: 0.6753\n",
      "Epoch 2/50\n",
      "308/308 [==============================] - 0s 235us/step - loss: 0.3879 - acc: 0.8149 - val_loss: 0.5550 - val_acc: 0.6753\n",
      "Epoch 3/50\n",
      "308/308 [==============================] - 0s 296us/step - loss: 0.4154 - acc: 0.7955 - val_loss: 0.5573 - val_acc: 0.6753\n",
      "Epoch 4/50\n",
      "308/308 [==============================] - 0s 305us/step - loss: 0.3916 - acc: 0.8247 - val_loss: 0.5555 - val_acc: 0.6883\n",
      "Epoch 5/50\n",
      "308/308 [==============================] - 0s 358us/step - loss: 0.4133 - acc: 0.8247 - val_loss: 0.5499 - val_acc: 0.6883\n",
      "Epoch 6/50\n",
      "308/308 [==============================] - 0s 314us/step - loss: 0.4275 - acc: 0.7890 - val_loss: 0.5459 - val_acc: 0.6494\n",
      "Epoch 7/50\n",
      "308/308 [==============================] - 0s 319us/step - loss: 0.4196 - acc: 0.8084 - val_loss: 0.5511 - val_acc: 0.6494\n",
      "Epoch 8/50\n",
      "308/308 [==============================] - 0s 285us/step - loss: 0.4171 - acc: 0.7825 - val_loss: 0.5540 - val_acc: 0.6753\n",
      "Epoch 9/50\n",
      "308/308 [==============================] - 0s 300us/step - loss: 0.3884 - acc: 0.8279 - val_loss: 0.5543 - val_acc: 0.6494\n",
      "Epoch 10/50\n",
      "308/308 [==============================] - 0s 282us/step - loss: 0.3850 - acc: 0.8247 - val_loss: 0.5432 - val_acc: 0.6883\n",
      "Epoch 11/50\n",
      "308/308 [==============================] - 0s 327us/step - loss: 0.4302 - acc: 0.8182 - val_loss: 0.5489 - val_acc: 0.6494\n",
      "Epoch 12/50\n",
      "308/308 [==============================] - 0s 285us/step - loss: 0.4175 - acc: 0.8377 - val_loss: 0.5593 - val_acc: 0.6494\n",
      "Epoch 13/50\n",
      "308/308 [==============================] - 0s 319us/step - loss: 0.4089 - acc: 0.8117 - val_loss: 0.5620 - val_acc: 0.6753\n",
      "Epoch 14/50\n",
      "308/308 [==============================] - 0s 293us/step - loss: 0.3858 - acc: 0.8442 - val_loss: 0.5655 - val_acc: 0.6883\n",
      "Epoch 15/50\n",
      "308/308 [==============================] - 0s 327us/step - loss: 0.4038 - acc: 0.8182 - val_loss: 0.5488 - val_acc: 0.6623\n",
      "Epoch 16/50\n",
      "308/308 [==============================] - 0s 313us/step - loss: 0.4179 - acc: 0.8182 - val_loss: 0.5456 - val_acc: 0.6494\n",
      "Epoch 17/50\n",
      "308/308 [==============================] - 0s 291us/step - loss: 0.3938 - acc: 0.8084 - val_loss: 0.5387 - val_acc: 0.6753\n",
      "Epoch 18/50\n",
      "308/308 [==============================] - 0s 395us/step - loss: 0.4285 - acc: 0.8117 - val_loss: 0.5453 - val_acc: 0.6753\n",
      "Epoch 19/50\n",
      "308/308 [==============================] - 0s 278us/step - loss: 0.4069 - acc: 0.8117 - val_loss: 0.5359 - val_acc: 0.6883\n",
      "Epoch 20/50\n",
      "308/308 [==============================] - 0s 309us/step - loss: 0.4198 - acc: 0.8149 - val_loss: 0.5625 - val_acc: 0.6623\n",
      "Epoch 21/50\n",
      "308/308 [==============================] - 0s 306us/step - loss: 0.4251 - acc: 0.8117 - val_loss: 0.5453 - val_acc: 0.6623\n",
      "Epoch 22/50\n",
      "308/308 [==============================] - 0s 271us/step - loss: 0.3967 - acc: 0.8182 - val_loss: 0.5535 - val_acc: 0.6623\n",
      "Epoch 23/50\n",
      "308/308 [==============================] - 0s 300us/step - loss: 0.4169 - acc: 0.8084 - val_loss: 0.5438 - val_acc: 0.6753\n",
      "Epoch 24/50\n",
      "308/308 [==============================] - 0s 301us/step - loss: 0.3736 - acc: 0.8279 - val_loss: 0.5532 - val_acc: 0.6753\n",
      "Epoch 25/50\n",
      "308/308 [==============================] - 0s 331us/step - loss: 0.4348 - acc: 0.7987 - val_loss: 0.5423 - val_acc: 0.6883\n",
      "Epoch 26/50\n",
      "308/308 [==============================] - 0s 280us/step - loss: 0.4181 - acc: 0.8084 - val_loss: 0.5465 - val_acc: 0.6883\n",
      "Epoch 27/50\n",
      "308/308 [==============================] - 0s 326us/step - loss: 0.3941 - acc: 0.8214 - val_loss: 0.5467 - val_acc: 0.6753\n",
      "Epoch 28/50\n",
      "308/308 [==============================] - 0s 326us/step - loss: 0.4079 - acc: 0.7955 - val_loss: 0.5348 - val_acc: 0.7013\n",
      "Epoch 29/50\n",
      "308/308 [==============================] - 0s 318us/step - loss: 0.4065 - acc: 0.8149 - val_loss: 0.5508 - val_acc: 0.6494\n",
      "Epoch 30/50\n",
      "308/308 [==============================] - 0s 323us/step - loss: 0.4030 - acc: 0.8279 - val_loss: 0.5322 - val_acc: 0.7013\n",
      "Epoch 31/50\n",
      "308/308 [==============================] - 0s 276us/step - loss: 0.3814 - acc: 0.8117 - val_loss: 0.5427 - val_acc: 0.6883\n",
      "Epoch 32/50\n",
      "308/308 [==============================] - 0s 302us/step - loss: 0.3882 - acc: 0.8214 - val_loss: 0.5427 - val_acc: 0.6753\n",
      "Epoch 33/50\n",
      "308/308 [==============================] - 0s 329us/step - loss: 0.3775 - acc: 0.8442 - val_loss: 0.5437 - val_acc: 0.7013\n",
      "Epoch 34/50\n",
      "308/308 [==============================] - 0s 282us/step - loss: 0.3586 - acc: 0.8474 - val_loss: 0.5573 - val_acc: 0.6753\n",
      "Epoch 35/50\n",
      "308/308 [==============================] - 0s 276us/step - loss: 0.3708 - acc: 0.8344 - val_loss: 0.5833 - val_acc: 0.6883\n",
      "Epoch 36/50\n",
      "308/308 [==============================] - 0s 346us/step - loss: 0.3761 - acc: 0.8182 - val_loss: 0.5804 - val_acc: 0.6753\n",
      "Epoch 37/50\n",
      "308/308 [==============================] - 0s 321us/step - loss: 0.3722 - acc: 0.8442 - val_loss: 0.5631 - val_acc: 0.6623\n",
      "Epoch 38/50\n",
      "308/308 [==============================] - 0s 284us/step - loss: 0.4119 - acc: 0.8247 - val_loss: 0.5558 - val_acc: 0.6753\n",
      "Epoch 39/50\n",
      "308/308 [==============================] - 0s 240us/step - loss: 0.3982 - acc: 0.8214 - val_loss: 0.5552 - val_acc: 0.6623\n",
      "Epoch 40/50\n",
      "308/308 [==============================] - 0s 596us/step - loss: 0.3681 - acc: 0.8377 - val_loss: 0.5724 - val_acc: 0.6494\n",
      "Epoch 41/50\n",
      "308/308 [==============================] - 0s 269us/step - loss: 0.4009 - acc: 0.8084 - val_loss: 0.5582 - val_acc: 0.6753\n",
      "Epoch 42/50\n",
      "308/308 [==============================] - 0s 302us/step - loss: 0.3915 - acc: 0.8214 - val_loss: 0.5746 - val_acc: 0.6623\n",
      "Epoch 43/50\n",
      "308/308 [==============================] - 0s 313us/step - loss: 0.4316 - acc: 0.7955 - val_loss: 0.5657 - val_acc: 0.6883\n",
      "Epoch 44/50\n",
      "308/308 [==============================] - 0s 329us/step - loss: 0.3728 - acc: 0.8377 - val_loss: 0.5779 - val_acc: 0.6494\n",
      "Epoch 45/50\n",
      "308/308 [==============================] - 0s 351us/step - loss: 0.4336 - acc: 0.7955 - val_loss: 0.5753 - val_acc: 0.6364\n",
      "Epoch 46/50\n",
      "308/308 [==============================] - 0s 229us/step - loss: 0.4136 - acc: 0.8149 - val_loss: 0.5579 - val_acc: 0.6623\n",
      "Epoch 47/50\n",
      "308/308 [==============================] - 0s 276us/step - loss: 0.4219 - acc: 0.8247 - val_loss: 0.5484 - val_acc: 0.6883\n",
      "Epoch 48/50\n",
      "308/308 [==============================] - 0s 605us/step - loss: 0.3715 - acc: 0.8506 - val_loss: 0.5693 - val_acc: 0.6623\n",
      "Epoch 49/50\n",
      "308/308 [==============================] - 0s 274us/step - loss: 0.3959 - acc: 0.7987 - val_loss: 0.5819 - val_acc: 0.6623\n",
      "Epoch 50/50\n",
      "308/308 [==============================] - 0s 269us/step - loss: 0.3698 - acc: 0.8377 - val_loss: 0.5763 - val_acc: 0.6623\n",
      "77/77 [==============================] - 0s 92us/step\n",
      "\n",
      "The accuracy of the current model is: 0.6623376662080939\n",
      "The chance that the Chiefs win is: 1.3629545320863797e-12 %\n"
     ]
    }
   ],
   "source": [
    "Predict('Chiefs','Panthers', 2020, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features used in this model were: ['Home_Pts_Scored', 'Away_Pts_Scored', 'Home_Pts_Al', 'Away_Pts_Al', 'Home_TDs', 'Away_Second_Al', 'Home_Rush_Plys_Al', 'Away_Rush_Plys_Al', 'Away_Pass_Plys_Al', 'Away_INTs', 'Home_Sacks_Gm', 'Home_PAT_Att', 'Away_PAT_Att']\n",
      "Train on 213 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "213/213 [==============================] - 1s 3ms/step - loss: 0.6661 - acc: 0.5728 - val_loss: 0.6632 - val_acc: 0.5741\n",
      "Epoch 2/50\n",
      "213/213 [==============================] - 0s 256us/step - loss: 0.6888 - acc: 0.5117 - val_loss: 0.6604 - val_acc: 0.5926\n",
      "Epoch 3/50\n",
      "213/213 [==============================] - 0s 261us/step - loss: 0.6662 - acc: 0.5493 - val_loss: 0.6567 - val_acc: 0.6296\n",
      "Epoch 4/50\n",
      "213/213 [==============================] - 0s 249us/step - loss: 0.6649 - acc: 0.5775 - val_loss: 0.6532 - val_acc: 0.6296\n",
      "Epoch 5/50\n",
      "213/213 [==============================] - 0s 377us/step - loss: 0.6640 - acc: 0.6150 - val_loss: 0.6487 - val_acc: 0.6111\n",
      "Epoch 6/50\n",
      "213/213 [==============================] - 0s 282us/step - loss: 0.6550 - acc: 0.5728 - val_loss: 0.6460 - val_acc: 0.6111\n",
      "Epoch 7/50\n",
      "213/213 [==============================] - 0s 360us/step - loss: 0.6550 - acc: 0.6009 - val_loss: 0.6414 - val_acc: 0.6111\n",
      "Epoch 8/50\n",
      "213/213 [==============================] - 0s 310us/step - loss: 0.6492 - acc: 0.5915 - val_loss: 0.6369 - val_acc: 0.6111\n",
      "Epoch 9/50\n",
      "213/213 [==============================] - 0s 424us/step - loss: 0.6556 - acc: 0.6479 - val_loss: 0.6345 - val_acc: 0.6296\n",
      "Epoch 10/50\n",
      "213/213 [==============================] - 0s 385us/step - loss: 0.6391 - acc: 0.6197 - val_loss: 0.6324 - val_acc: 0.6481\n",
      "Epoch 11/50\n",
      "213/213 [==============================] - 0s 383us/step - loss: 0.6420 - acc: 0.6056 - val_loss: 0.6310 - val_acc: 0.6481\n",
      "Epoch 12/50\n",
      "213/213 [==============================] - 0s 337us/step - loss: 0.6263 - acc: 0.6526 - val_loss: 0.6272 - val_acc: 0.6667\n",
      "Epoch 13/50\n",
      "213/213 [==============================] - 0s 323us/step - loss: 0.6531 - acc: 0.6103 - val_loss: 0.6262 - val_acc: 0.6481\n",
      "Epoch 14/50\n",
      "213/213 [==============================] - 0s 382us/step - loss: 0.6414 - acc: 0.6338 - val_loss: 0.6228 - val_acc: 0.6667\n",
      "Epoch 15/50\n",
      "213/213 [==============================] - 0s 355us/step - loss: 0.6288 - acc: 0.6667 - val_loss: 0.6201 - val_acc: 0.6852\n",
      "Epoch 16/50\n",
      "213/213 [==============================] - 0s 388us/step - loss: 0.6316 - acc: 0.6714 - val_loss: 0.6162 - val_acc: 0.7037\n",
      "Epoch 17/50\n",
      "213/213 [==============================] - 0s 343us/step - loss: 0.6224 - acc: 0.6667 - val_loss: 0.6145 - val_acc: 0.7037\n",
      "Epoch 18/50\n",
      "213/213 [==============================] - 0s 401us/step - loss: 0.6268 - acc: 0.6714 - val_loss: 0.6127 - val_acc: 0.7037\n",
      "Epoch 19/50\n",
      "213/213 [==============================] - 0s 320us/step - loss: 0.6264 - acc: 0.6854 - val_loss: 0.6110 - val_acc: 0.7037\n",
      "Epoch 20/50\n",
      "213/213 [==============================] - 0s 297us/step - loss: 0.6151 - acc: 0.6808 - val_loss: 0.6104 - val_acc: 0.7222\n",
      "Epoch 21/50\n",
      "213/213 [==============================] - 0s 355us/step - loss: 0.6050 - acc: 0.7042 - val_loss: 0.6080 - val_acc: 0.7037\n",
      "Epoch 22/50\n",
      "213/213 [==============================] - 0s 340us/step - loss: 0.6061 - acc: 0.6901 - val_loss: 0.6055 - val_acc: 0.7037\n",
      "Epoch 23/50\n",
      "213/213 [==============================] - 0s 369us/step - loss: 0.6306 - acc: 0.7042 - val_loss: 0.6042 - val_acc: 0.7222\n",
      "Epoch 24/50\n",
      "213/213 [==============================] - 0s 350us/step - loss: 0.6130 - acc: 0.7042 - val_loss: 0.6023 - val_acc: 0.7222\n",
      "Epoch 25/50\n",
      "213/213 [==============================] - 0s 395us/step - loss: 0.6138 - acc: 0.7089 - val_loss: 0.6006 - val_acc: 0.7222\n",
      "Epoch 26/50\n",
      "213/213 [==============================] - 0s 294us/step - loss: 0.6215 - acc: 0.6948 - val_loss: 0.6002 - val_acc: 0.7222\n",
      "Epoch 27/50\n",
      "213/213 [==============================] - 0s 247us/step - loss: 0.6115 - acc: 0.7136 - val_loss: 0.5995 - val_acc: 0.7222\n",
      "Epoch 28/50\n",
      "213/213 [==============================] - 0s 330us/step - loss: 0.6001 - acc: 0.7136 - val_loss: 0.5973 - val_acc: 0.7222\n",
      "Epoch 29/50\n",
      "213/213 [==============================] - 0s 309us/step - loss: 0.5963 - acc: 0.7183 - val_loss: 0.5959 - val_acc: 0.7222\n",
      "Epoch 30/50\n",
      "213/213 [==============================] - 0s 332us/step - loss: 0.5834 - acc: 0.7183 - val_loss: 0.5941 - val_acc: 0.7222\n",
      "Epoch 31/50\n",
      "213/213 [==============================] - 0s 303us/step - loss: 0.5913 - acc: 0.7277 - val_loss: 0.5928 - val_acc: 0.7222\n",
      "Epoch 32/50\n",
      "213/213 [==============================] - 0s 321us/step - loss: 0.5996 - acc: 0.7042 - val_loss: 0.5916 - val_acc: 0.7222\n",
      "Epoch 33/50\n",
      "213/213 [==============================] - 0s 422us/step - loss: 0.5830 - acc: 0.7324 - val_loss: 0.5903 - val_acc: 0.7222\n",
      "Epoch 34/50\n",
      "213/213 [==============================] - 0s 308us/step - loss: 0.5964 - acc: 0.7089 - val_loss: 0.5885 - val_acc: 0.7222\n",
      "Epoch 35/50\n",
      "213/213 [==============================] - 0s 315us/step - loss: 0.5794 - acc: 0.7324 - val_loss: 0.5870 - val_acc: 0.7037\n",
      "Epoch 36/50\n",
      "213/213 [==============================] - 0s 349us/step - loss: 0.5581 - acc: 0.7371 - val_loss: 0.5856 - val_acc: 0.7037\n",
      "Epoch 37/50\n",
      "213/213 [==============================] - 0s 377us/step - loss: 0.5957 - acc: 0.7042 - val_loss: 0.5857 - val_acc: 0.7222\n",
      "Epoch 38/50\n",
      "213/213 [==============================] - 0s 388us/step - loss: 0.5596 - acc: 0.7371 - val_loss: 0.5840 - val_acc: 0.7222\n",
      "Epoch 39/50\n",
      "213/213 [==============================] - 0s 252us/step - loss: 0.5691 - acc: 0.7512 - val_loss: 0.5832 - val_acc: 0.7222\n",
      "Epoch 40/50\n",
      "213/213 [==============================] - 0s 285us/step - loss: 0.5590 - acc: 0.7465 - val_loss: 0.5824 - val_acc: 0.7222\n",
      "Epoch 41/50\n",
      "213/213 [==============================] - 0s 284us/step - loss: 0.5832 - acc: 0.7136 - val_loss: 0.5817 - val_acc: 0.7037\n",
      "Epoch 42/50\n",
      "213/213 [==============================] - 0s 256us/step - loss: 0.5702 - acc: 0.7512 - val_loss: 0.5804 - val_acc: 0.7222\n",
      "Epoch 43/50\n",
      "213/213 [==============================] - 0s 342us/step - loss: 0.5778 - acc: 0.7465 - val_loss: 0.5795 - val_acc: 0.7037\n",
      "Epoch 44/50\n",
      "213/213 [==============================] - 0s 404us/step - loss: 0.5783 - acc: 0.7324 - val_loss: 0.5790 - val_acc: 0.7037\n",
      "Epoch 45/50\n",
      "213/213 [==============================] - 0s 367us/step - loss: 0.5548 - acc: 0.7371 - val_loss: 0.5781 - val_acc: 0.7037\n",
      "Epoch 46/50\n",
      "213/213 [==============================] - 0s 303us/step - loss: 0.5614 - acc: 0.7183 - val_loss: 0.5772 - val_acc: 0.7037\n",
      "Epoch 47/50\n",
      "213/213 [==============================] - 0s 302us/step - loss: 0.5735 - acc: 0.7465 - val_loss: 0.5768 - val_acc: 0.7037\n",
      "Epoch 48/50\n",
      "213/213 [==============================] - 0s 318us/step - loss: 0.5621 - acc: 0.7324 - val_loss: 0.5758 - val_acc: 0.7037\n",
      "Epoch 49/50\n",
      "213/213 [==============================] - 0s 360us/step - loss: 0.5523 - acc: 0.7277 - val_loss: 0.5749 - val_acc: 0.7037\n",
      "Epoch 50/50\n",
      "213/213 [==============================] - 0s 352us/step - loss: 0.5914 - acc: 0.7042 - val_loss: 0.5742 - val_acc: 0.6852\n",
      "54/54 [==============================] - 0s 51us/step\n",
      "\n",
      "The accuracy of the current model is: 0.6851851918079235\n",
      "The chance that the Chiefs win is: 99.74831938743591 %\n"
     ]
    }
   ],
   "source": [
    "Predict_Win('Chiefs','Texans', 2020,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Home_Pts_Scored', 'Away_Pts_Scored', 'Home_Pts_Al', 'Away_Pts_Al', 'Home_TDs', 'Away_Second_Al', 'Home_Rush_Plys_Al', 'Away_Rush_Plys_Al', 'Away_INTs', 'Home_Sacks_Gm', 'Home_PAT_Att', 'Away_PAT_Att', 'Away_Pass_Plys_Al', 'Home_Pass_Att']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
